name: "preprocess"
backend: "python"
max_batch_size: 16 
input [
{
    name: "inp_image"
    data_type: TYPE_UINT8   
    dims: [ -1, -1, 3 ]
}
]
 
output [
{
    name: "preprocess_image"
    data_type: TYPE_FP32
    dims: [ 3, 416, 416 ]
}
]

instance_group [{ kind: KIND_CPU }]

parameters: {
  key: "EXECUTION_ENV_PATH",
  value: {string_value: "/models/text_region_extractor/triton_infer.tar.gz"}
}